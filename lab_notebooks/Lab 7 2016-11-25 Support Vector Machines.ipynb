{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016-11-25: Support Vector Machines\n",
    "In this lab, we will apply support vector classification methods to the Endometrium vs. Uterus cancer data. For documentation see: http://scikit-learn.org/0.17/modules/svm.html#svm\n",
    "\n",
    "Let us start, as usual, by setting up our environment, loading the data, and setting up our cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a stratified 10-fold cross-validation\n",
    "from sklearn import cross_validation\n",
    "folds = cross_validation.StratifiedKFold(y, 10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM decision function\n",
    "\n",
    "SVMs do not naturally compute probabilities. It is possible to convert the output of the decision function into a probability, but that is a computationally intensive procedure, called Platt's scaling. You can read about it in the corresponding paper: https://www.microsoft.com/en-us/research/publication/probabilities-for-sv-machines/ \n",
    "\n",
    "The natural ways for SVMs to return scores (and not predicted classes) is to use the output of their decision function directly.\n",
    "\n",
    "**Question:** Modify the `cross_validate` function to return as predictions the values of the decision function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate(design_matrix, labels, classifier, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns, for each data point x, \n",
    "    the value of the decision function f computed when x was part of the test set. \n",
    "   \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  sklearn classifier object\n",
    "        Classifier instance; must have the following methods:\n",
    "        - fit(X, y) to train the classifier on the data X, y\n",
    "        - decision_function(X) to apply the trained classifier to the data X \n",
    "        and return probability estimates \n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    pred = np.zeros(labels.shape) # Hold all predictions, in correct order.\n",
    "    for tr, te in cv_folds:\n",
    "        # Restrict data to train/test folds\n",
    "        Xtr = design_matrix[tr, :]\n",
    "        ytr = labels[tr]\n",
    "        Xte = design_matrix[te, :]\n",
    "        \n",
    "        # Fit classifier\n",
    "        classifier.fit(Xtr, ytr)\n",
    "\n",
    "        # Compute decision function on test data\n",
    "        # TODO \n",
    "        \n",
    "        # Update pred \n",
    "        # TODO \n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with default C value\n",
    "\n",
    "Let us cross-validate an SVM with linear kernel (linear soft-margin SVM) with default C parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear') \n",
    "ypred_linear = cross_validate(X, y, clf, folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Plot the corresponding ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = # TODO\n",
    "auc = # TODO\n",
    "\n",
    "plt.plot(, #TODO\n",
    "         color='orange',\n",
    "         label='Linear SVM (AUC=%.2f)' % auc)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.legend(loc=(1.1, 0), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of support vectors\n",
    "\n",
    "The `n_support_` argument of an svm classifier gives us the number of support vectors for each class.\n",
    "\n",
    "**Question:** How many support vectors does our classifier have? How many is this compared to the number of training samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel matrix\n",
    "\n",
    "The kernel matrix is the matrix of size $n \\times n$ that has for entry $K_{ij}$ the value $k(x^i, x^j)$, where $k$ is the kernel function used.\n",
    "\n",
    "In the case of the linear kernel, the kernel function is the dot product.\n",
    "\n",
    "**Question** Plot the matrix K for the linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmatrix = # TODO\n",
    "\n",
    "# heatmap + color map\n",
    "plt.pcolor(kmatrix, cmap=matplotlib.cm.PuRd) \n",
    "\n",
    "# plot colorbar to the right\n",
    "plt.colorbar()\n",
    "\n",
    "# set axes boundaries\n",
    "plt.xlim([0, X.shape[0]])\n",
    "plt.ylim([0, X.shape[0]])\n",
    "\n",
    "# flip the y-axis\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().xaxis.tick_top()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you observe about the values taken by the kernel? What happens if you scale the data before computing the kernel? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does scaling affect the performance of the linear SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_with_scaling(design_matrix, labels, classifier, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns, for each data point x, \n",
    "    the value of the decision function f computed when x was part of the test set. \n",
    "    \n",
    "    Scale the training data, and apply same scaling to the test data.\n",
    "   \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  sklearn classifier object\n",
    "        Classifier instance; must have the following methods:\n",
    "        - fit(X, y) to train the classifier on the data X, y\n",
    "        - decision_function(X) to apply the trained classifier to the data X \n",
    "        and return probability estimates \n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    pred = np.zeros(labels.shape)\n",
    "    for tr, te in cv_folds:\n",
    "        # Restrict data to train/test folds\n",
    "        Xtr = design_matrix[tr, :]\n",
    "        ytr = labels[tr]\n",
    "        Xte = design_matrix[te, :]\n",
    "        \n",
    "        # Create scaler object\n",
    "        # TODO \n",
    "        \n",
    "        # Fit the scaler and transform training data\n",
    "        # TODO \n",
    "        \n",
    "        # Transform test data\n",
    "        # TODO\n",
    "        \n",
    "        # Fit classifier\n",
    "        classifier.fit(Xtr, ytr)\n",
    "\n",
    "        # Compute decision function on test data\n",
    "        # TODO\n",
    "        \n",
    "        # Update pred\n",
    "        # TODO\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear') \n",
    "ypred_linear_scaled = cross_validate_with_scaling(X, y, clf, folds)\n",
    "\n",
    "# TODO\n",
    "\n",
    "plt.plot(, #TODO\n",
    "            label='Linear SVM (AUC=%.2f)' % auc)\n",
    "plt.plot(, #TODO\n",
    "            label='Linear SVM + scaling (AUC=%.2f)' % auc2)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curves', fontsize=16)\n",
    "plt.legend(loc=(1.1, 0), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Now optimize for the C-parameter within each loop of the cross-validation. Plot the new ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "parameters_dict = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SVMs with kernels of the form $k(x, x') = (\\langle x, x' \\rangle + r)^d$.\n",
    "\n",
    "**Question** Plot kernel matrices for $r=0, d=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you observe? What is going to happen if you increase $d$? How do you think this will affect the SVM? Cross-validate the SVM and plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "# Plot\n",
    "plt.plot(, #TODO\n",
    "            label='Linear SVM + scaling (AUC=%.2f)' % auc2)\n",
    "plt.plot(, #TODO\n",
    "            label='Quadratic SVM (AUC=%.2f)' % auc3)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curves', fontsize=16)\n",
    "plt.legend(loc=(1.1, 0), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What value for $r$ can change this behavior? Plot the corresponding kernel matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Now evaluate an SVM with polynomial kernel of degree d=2 and value for r as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "# Plot\n",
    "plt.plot(, #TODO\n",
    "            label='Linear SVM + scaling (AUC=%.2f)' % auc2)\n",
    "plt.plot(, #TODO\n",
    "            label='Quadratic SVM (AUC=%.2f)' % auc4)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curves', fontsize=16)\n",
    "plt.legend(loc=(1.1, 0), fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian RBF kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SVMs with kernels of the form $k(x, x') = \\exp \\left(-\\gamma ||x - x'||^2 \\right)$.\n",
    "\n",
    "The following code efficiently computes the pairwise squared distances between all items in X, that is to say the matrix $P$ such that $P_{ij} = ||x^i - x^j||^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "pairwise_sq_dists = squareform(pdist(X, 'sqeuclidean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Plot kernel matrices for varying values of $\\gamma$. What do you observe? What is going to be the impact on the SVM? What happens with very very small values of $\\gamma$? Check your intuitions by cross-validating SVMs with these various kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Bonus) Scaling the kernel matrix.\n",
    "\n",
    "What we have observed here is a phenomenon of diagonal dominance in the kernel matrix. \n",
    "\n",
    "One way to address this is to re-scale the kernel matrix in the following way:\n",
    "$\\hat K_{ij} = \\frac{K_{ij}}{\\sqrt{K_{ii} K_{jj}}}$.\n",
    "\n",
    "To implement this you can pass your own kernel function or matrix to the `kernel` parameter of the SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Write a function `scaled_quadratic_kernel` that computes the scaled quadratic kernel matrix between two data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaled_quadratic_kernel(X1, X2):\n",
    "    \n",
    "    \"\"\" Custom scaled RBF kernel.\n",
    "    \n",
    "    The RBF kernel between X1 and X2 is scaled to avoid diagonal dominance,\n",
    "    by applying k(X1i, X2j) <-- k(X1i, X2j) / sqrt(k(X1i, X1i) k(X2j, X2j))   \n",
    "   \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X1: (n_samples1, n_features) np.array\n",
    "        First data matrix.\n",
    "    X2: (n_samples2, n_features) np.array\n",
    "        Second data matrix.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    K: (n_samples1, n_samples2) np.array\n",
    "        Kernel matrix between samples from X1 and samples from X2.\n",
    "    \"\"\"\n",
    "    # TODO   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Plot the corresponding kernel matrix. Does it match your expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** In the 0.17 version of scikit-learn, it isn't possible to use a custom kernel function within GridSearchCV. Set the C parameter to 1 and compare your custom kernel with the quadratic kernel (d=2) on the gene expression data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
